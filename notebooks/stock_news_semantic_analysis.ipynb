{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DA2tTnlQjZy"
      },
      "source": [
        "# Financial Stock News Analysis for Stock Rise or Fall Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RQREEVdWQzco",
        "outputId": "1894f702-0470-4021-9b02-6da7c971407f"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YLLSDoAMbE0I"
      },
      "outputs": [],
      "source": [
        "acl_train = load_dataset(\"TheFinAI/flare-sm-acl\", split=\"train\")\n",
        "acl_test = load_dataset(\"TheFinAI/flare-sm-acl\", split=\"test\")\n",
        "acl_valid = load_dataset(\"TheFinAI/flare-sm-acl\", split=\"valid\")\n",
        "\n",
        "acl_train_df = acl_train.to_pandas()[['gold', 'text']]\n",
        "acl_valid_df = acl_valid.to_pandas()[['gold', 'text']]\n",
        "acl_test_df = acl_test.to_pandas()[['gold', 'text']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu9tDJuu-qDo"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NoEM5P4lQwxo"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2') # load pre-trained model for text embedding\n",
        "\n",
        "# Text embedding with batch processing\n",
        "def batch_encode(texts, batch_size=32):\n",
        "    def get_sbert_embeddings(texts):\n",
        "        embeddings = model.encode(texts, convert_to_numpy=True)\n",
        "        return embeddings\n",
        "    embeddings_list = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i + batch_size]\n",
        "        batch_embeddings = get_sbert_embeddings(batch)\n",
        "        embeddings_list.append(batch_embeddings)\n",
        "    return np.vstack(embeddings_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "85cP-6q-Q9x2"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# training data processing\n",
        "texts = acl_train_df['text'].tolist()\n",
        "X_train_embeddings = batch_encode(texts)\n",
        "X_train_embeddings = np.array(X_train_embeddings, dtype=np.float32)\n",
        "acl_train_embedded = np.concatenate([acl_train_df[['gold']], X_train_embeddings], axis=1)\n",
        "acl_train_embedded_jax = jnp.array(acl_train_embedded, dtype=jnp.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aTPnCGTzSl8i"
      },
      "outputs": [],
      "source": [
        "# validation data processing\n",
        "valid_texts = acl_valid_df['text'].tolist()\n",
        "X_valid_embeddings = batch_encode(valid_texts)\n",
        "X_valid_embeddings = np.array(X_valid_embeddings, dtype=np.float32)\n",
        "acl_valid_embedded = np.concatenate([acl_valid_df[['gold']], X_valid_embeddings], axis=1)\n",
        "acl_valid_embedded_jax = jnp.array(acl_valid_embedded, dtype=jnp.float32)\n",
        "\n",
        "# test data processing\n",
        "test_texts = acl_test_df['text'].tolist()\n",
        "X_test_embeddings = batch_encode(test_texts)\n",
        "X_test_embeddings = np.array(X_test_embeddings, dtype=np.float32)\n",
        "acl_test_embedded = np.concatenate([acl_test_df[['gold']], X_test_embeddings], axis=1)\n",
        "acl_test_embedded_jax = jnp.array(acl_test_embedded, dtype=jnp.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gNW-7F4-jBh",
        "outputId": "05cb9d5f-ec82-4eb1-ef1c-a5556c7b3436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.         -0.00104386 -0.01534523 ... -0.06044362 -0.04032706\n",
            "   0.04581903]\n",
            " [ 1.         -0.01484505 -0.01614804 ... -0.05998763 -0.04143053\n",
            "   0.04037761]\n",
            " [ 0.         -0.00950439 -0.01646532 ... -0.06522585 -0.03886714\n",
            "   0.03963048]]\n",
            "[[ 1.         -0.00104386 -0.01534523 ... -0.06044362 -0.04032706\n",
            "   0.04581903]\n",
            " [ 1.         -0.01484505 -0.01614804 ... -0.05998763 -0.04143053\n",
            "   0.04037761]\n",
            " [ 0.         -0.00950439 -0.01646532 ... -0.06522585 -0.03886714\n",
            "   0.03963048]]\n",
            "(20781, 385)\n",
            "(2555, 385)\n"
          ]
        }
      ],
      "source": [
        "print(acl_train_embedded[:3])\n",
        "print(acl_train_embedded_jax[:3])\n",
        "print(acl_train_embedded.shape)\n",
        "print(acl_valid_embedded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv48-cZA-uuC"
      },
      "source": [
        "## Train the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ViiZbQS2XK"
      },
      "source": [
        "### 1. Baseline model -- XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "db274R5inu2f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyN3ksOb-yu8"
      },
      "source": [
        "Prepare data for training. Split training data into X and response Y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yHcxwjG94DOU"
      },
      "outputs": [],
      "source": [
        "y_train = acl_train_embedded[:, 0].reshape(-1, 1)\n",
        "X_train = acl_train_embedded[:, 1:]\n",
        "y_valid = acl_valid_embedded[:, 0].reshape(-1, 1)\n",
        "X_valid = acl_valid_embedded[:, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp1DrbZG-6aO"
      },
      "source": [
        "Define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dVVc5V4n8OP",
        "outputId": "a67eb394-d435-40d4-c4ce-3424024445b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class distribution in training data: {np.float64(0.0): np.int64(10305), np.float64(1.0): np.int64(10476)}\n"
          ]
        }
      ],
      "source": [
        "# Check class balance\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "class_distribution = dict(zip(unique, counts))\n",
        "print(\"\\nClass distribution in training data:\", class_distribution)\n",
        "\n",
        "# Apply SMOTE for class balancing if imbalanced\n",
        "if len(unique) > 1 and min(counts) / max(counts) < 0.8:\n",
        "    print(\"Applying SMOTE to balance classes...\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train.ravel())\n",
        "    # Convert back to original shape\n",
        "    X_train = X_train_resampled\n",
        "    y_train = y_train_resampled.reshape(-1, 1)\n",
        "    print(\"After SMOTE - samples:\", X_train.shape[0])\n",
        "\n",
        "# Create a pipeline with standardization and XGBoost\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss'\n",
        "    ))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "wJmv50mQoBcT",
        "outputId": "75f38f91-aa36-43c7-aace-3d09012e00a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tuning XGBoost hyperparameters...\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:16:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                             (&#x27;clf&#x27;,\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            device=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enable_categorical=False,\n",
              "                                                            eval_metric=&#x27;logloss&#x27;,\n",
              "                                                            feature_types=None,\n",
              "                                                            gamma=None,\n",
              "                                                            grow_policy=None,\n",
              "                                                            importa...\n",
              "                                                            random_state=42, ...))]),\n",
              "                   n_iter=20, n_jobs=-1,\n",
              "                   param_distributions={&#x27;clf__colsample_bytree&#x27;: [0.6, 0.8,\n",
              "                                                                  1.0],\n",
              "                                        &#x27;clf__gamma&#x27;: [0, 0.1, 0.2],\n",
              "                                        &#x27;clf__learning_rate&#x27;: [0.01, 0.05, 0.1,\n",
              "                                                               0.2],\n",
              "                                        &#x27;clf__max_depth&#x27;: [3, 4, 5, 6, 8],\n",
              "                                        &#x27;clf__min_child_weight&#x27;: [1, 3, 5],\n",
              "                                        &#x27;clf__n_estimators&#x27;: [50, 100, 200,\n",
              "                                                              300],\n",
              "                                        &#x27;clf__subsample&#x27;: [0.6, 0.8, 1.0]},\n",
              "                   random_state=210, scoring=&#x27;matthews_corrcoef&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                             (&#x27;clf&#x27;,\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            device=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enable_categorical=False,\n",
              "                                                            eval_metric=&#x27;logloss&#x27;,\n",
              "                                                            feature_types=None,\n",
              "                                                            gamma=None,\n",
              "                                                            grow_policy=None,\n",
              "                                                            importa...\n",
              "                                                            random_state=42, ...))]),\n",
              "                   n_iter=20, n_jobs=-1,\n",
              "                   param_distributions={&#x27;clf__colsample_bytree&#x27;: [0.6, 0.8,\n",
              "                                                                  1.0],\n",
              "                                        &#x27;clf__gamma&#x27;: [0, 0.1, 0.2],\n",
              "                                        &#x27;clf__learning_rate&#x27;: [0.01, 0.05, 0.1,\n",
              "                                                               0.2],\n",
              "                                        &#x27;clf__max_depth&#x27;: [3, 4, 5, 6, 8],\n",
              "                                        &#x27;clf__min_child_weight&#x27;: [1, 3, 5],\n",
              "                                        &#x27;clf__n_estimators&#x27;: [50, 100, 200,\n",
              "                                                              300],\n",
              "                                        &#x27;clf__subsample&#x27;: [0.6, 0.8, 1.0]},\n",
              "                   random_state=210, scoring=&#x27;matthews_corrcoef&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=0.8, device=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "                               feature_types=None, gamma=0, grow_policy=None,\n",
              "                               importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.01,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=3, max_leaves=None, min_child_weight=1,\n",
              "                               missing=nan, monotone_constraints=None,\n",
              "                               multi_strategy=None, n_estimators=100,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               random_state=42, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=0, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
              "              max_leaves=None, min_child_weight=1, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                             ('clf',\n",
              "                                              XGBClassifier(base_score=None,\n",
              "                                                            booster=None,\n",
              "                                                            callbacks=None,\n",
              "                                                            colsample_bylevel=None,\n",
              "                                                            colsample_bynode=None,\n",
              "                                                            colsample_bytree=None,\n",
              "                                                            device=None,\n",
              "                                                            early_stopping_rounds=None,\n",
              "                                                            enable_categorical=False,\n",
              "                                                            eval_metric='logloss',\n",
              "                                                            feature_types=None,\n",
              "                                                            gamma=None,\n",
              "                                                            grow_policy=None,\n",
              "                                                            importa...\n",
              "                                                            random_state=42, ...))]),\n",
              "                   n_iter=20, n_jobs=-1,\n",
              "                   param_distributions={'clf__colsample_bytree': [0.6, 0.8,\n",
              "                                                                  1.0],\n",
              "                                        'clf__gamma': [0, 0.1, 0.2],\n",
              "                                        'clf__learning_rate': [0.01, 0.05, 0.1,\n",
              "                                                               0.2],\n",
              "                                        'clf__max_depth': [3, 4, 5, 6, 8],\n",
              "                                        'clf__min_child_weight': [1, 3, 5],\n",
              "                                        'clf__n_estimators': [50, 100, 200,\n",
              "                                                              300],\n",
              "                                        'clf__subsample': [0.6, 0.8, 1.0]},\n",
              "                   random_state=210, scoring='matthews_corrcoef', verbose=1)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'clf__n_estimators': [50, 100, 200, 300],\n",
        "    'clf__max_depth': [3, 4, 5, 6, 8],\n",
        "    'clf__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'clf__subsample': [0.6, 0.8, 1.0],\n",
        "    'clf__colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'clf__min_child_weight': [1, 3, 5],\n",
        "    'clf__gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV for efficient hyperparameter tuning\n",
        "print(\"\\nTuning XGBoost hyperparameters...\")\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipe,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,  # Number of parameter settings to try\n",
        "    cv=5,\n",
        "    scoring='matthews_corrcoef',\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=210\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmSB-jz-oGJ3",
        "outputId": "a4e0853a-8300-471c-d3ce-c8b0070546a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best parameters: {'clf__subsample': 0.6, 'clf__n_estimators': 100, 'clf__min_child_weight': 1, 'clf__max_depth': 3, 'clf__learning_rate': 0.01, 'clf__gamma': 0, 'clf__colsample_bytree': 0.8}\n",
            "Best cross-validation MCC: 0.0840\n"
          ]
        }
      ],
      "source": [
        "# Get best parameters and model\n",
        "print(f\"\\nBest parameters: {random_search.best_params_}\")\n",
        "print(f\"Best cross-validation MCC: {random_search.best_score_:.4f}\")\n",
        "\n",
        "# Train optimized model with best parameters\n",
        "best_xgb_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_pred = best_xgb_model.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131p4D6koH5G",
        "outputId": "446e9415-4dac-4b03-e987-40f53d5cfa71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optimized XGBoost Results:\n",
            "Validation Accuracy: 0.5319\n",
            "Matthews Correlation Coefficient: 0.0290\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.47      0.35      0.40      1139\n",
            "         1.0       0.56      0.68      0.62      1416\n",
            "\n",
            "    accuracy                           0.53      2555\n",
            "   macro avg       0.52      0.51      0.51      2555\n",
            "weighted avg       0.52      0.53      0.52      2555\n",
            "\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "1. Feature 107: 0.0401\n",
            "2. Feature 133: 0.0280\n",
            "3. Feature 39: 0.0276\n",
            "4. Feature 196: 0.0263\n",
            "5. Feature 186: 0.0262\n",
            "6. Feature 298: 0.0258\n",
            "7. Feature 234: 0.0243\n",
            "8. Feature 245: 0.0237\n",
            "9. Feature 276: 0.0228\n",
            "10. Feature 66: 0.0227\n"
          ]
        }
      ],
      "source": [
        "# Calculate MCC for XGBoost\n",
        "xgb_mcc = matthews_corrcoef(y_valid, y_pred)\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"\\nOptimized XGBoost Results:\")\n",
        "print(f\"Validation Accuracy: {best_xgb_model.score(X_valid, y_valid):.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient: {xgb_mcc:.4f}\")\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_valid, y_pred))\n",
        "\n",
        "# Feature importance analysis\n",
        "if hasattr(best_xgb_model[-1], 'feature_importances_'):\n",
        "    importances = best_xgb_model[-1].feature_importances_\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    indices = np.argsort(importances)[::-1][:10]\n",
        "    for i, idx in enumerate(indices):\n",
        "        print(f\"{i+1}. Feature {idx}: {importances[idx]:.4f}\")\n",
        "\n",
        "# Store the model for comparison with other methods\n",
        "baseline_model = best_xgb_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnjmiWjNS9ms"
      },
      "source": [
        "### 2. Train a MLP with JAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX511UFt-77w"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from typing import List, Tuple, Any\n",
        "import optax  # For Adam optimizer\n",
        "from functools import partial\n",
        "\n",
        "# Prepare data for modelling\n",
        "y_train = acl_train_embedded_jax[:, 0].reshape(-1, 1)\n",
        "X_train = acl_train_embedded_jax[:, 1:]\n",
        "y_valid = acl_valid_embedded_jax[:, 0].reshape(-1, 1)\n",
        "X_valid = acl_valid_embedded_jax[:, 1:]\n",
        "input_dim = X_train.shape[1]  # Get input dimension from training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHNYQxYgR7o-"
      },
      "outputs": [],
      "source": [
        "# Define MLP in JAX\n",
        "def init_mlp_params(layer_sizes: List[int], key: Any) -> List[Tuple[jnp.ndarray, jnp.ndarray]]:\n",
        "    params = []\n",
        "    keys = random.split(key, len(layer_sizes))\n",
        "    for in_dim, out_dim, k in zip(layer_sizes[:-1], layer_sizes[1:], keys):\n",
        "        w_key, b_key = random.split(k)\n",
        "        W = random.normal(w_key, (in_dim, out_dim)) * jnp.sqrt(2. / in_dim)\n",
        "        b = jnp.zeros((out_dim,))\n",
        "        params.append((W, b))\n",
        "    return params\n",
        "\n",
        "def mlp_forward(params: List[Tuple[jnp.ndarray, jnp.ndarray]], x: jnp.ndarray, dropout_rate: float = 0.0,\n",
        "               train: bool = False, key: Any = None) -> jnp.ndarray:\n",
        "    \"\"\"Forward pass with dropout support\"\"\"\n",
        "    for i, (W, b) in enumerate(params[:-1]):\n",
        "        x = jnp.dot(x, W) + b\n",
        "        x = jax.nn.relu(x)\n",
        "\n",
        "        # Apply dropout during training\n",
        "        if train and dropout_rate > 0:\n",
        "            if key is None:\n",
        "                raise ValueError(\"Random key required for dropout\")\n",
        "            dropout_key = random.fold_in(key, i)  # Different key for each layer\n",
        "            mask = random.bernoulli(dropout_key, p=1-dropout_rate, shape=x.shape)\n",
        "            x = x * mask / (1 - dropout_rate)  # Scale to maintain expected value\n",
        "\n",
        "    W_last, b_last = params[-1]\n",
        "    logits = jnp.dot(x, W_last) + b_last\n",
        "    return logits\n",
        "\n",
        "# Loss and training step\n",
        "def binary_cross_entropy_loss(logits: jnp.ndarray, labels: jnp.ndarray) -> jnp.ndarray:\n",
        "    preds = jax.nn.sigmoid(logits)\n",
        "    return -jnp.mean(labels * jnp.log(preds + 1e-7) + (1 - labels) * jnp.log(1 - preds + 1e-7))\n",
        "\n",
        "# Improved training step with Adam optimizer\n",
        "@partial(jax.jit, static_argnums=(4, 5))\n",
        "def train_step(params, X_batch, y_batch, opt_state, dropout_rate=0.2, train=True):\n",
        "    \"\"\"Single training step with Adam optimizer and dropout\"\"\"\n",
        "    key = random.PRNGKey(0)  # For reproducibility\n",
        "\n",
        "    def loss_fn(p):\n",
        "        logits = mlp_forward(p, X_batch, dropout_rate=dropout_rate, train=train, key=key)\n",
        "        return binary_cross_entropy_loss(logits, y_batch)\n",
        "\n",
        "    loss, grads = jax.value_and_grad(loss_fn)(params)\n",
        "    updates, new_opt_state = optimizer.update(grads, opt_state)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, new_opt_state, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg260zcbV7s8"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning\n",
        "def tune_hyperparameters():\n",
        "    best_accuracy = 0.0\n",
        "    best_params = None\n",
        "    best_config = {}\n",
        "\n",
        "    # Define hyperparameter search space\n",
        "    learning_rates = [1e-4]\n",
        "    hidden_layer_configs = [\n",
        "        [128, 64]\n",
        "    ]\n",
        "    dropout_rates = [0.0, 0.2, 0.3, 0.4, 0.5, 0.6, .7, .8, .9]\n",
        "    batch_sizes = [32]  # For mini-batch training\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for lr in learning_rates:\n",
        "        for hidden_layers in hidden_layer_configs:\n",
        "            for dropout_rate in dropout_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    print(f\"\\nTrying: lr={lr}, layers={hidden_layers}, dropout={dropout_rate}, batch_size={batch_size}\")\n",
        "\n",
        "                    # Initialize model\n",
        "                    key = random.PRNGKey(42)\n",
        "                    layer_sizes = [input_dim] + hidden_layers + [1]\n",
        "                    params = init_mlp_params(layer_sizes, key)\n",
        "\n",
        "                    # Initialize optimizer\n",
        "                    global optimizer  # Make it accessible in train_step\n",
        "                    optimizer = optax.adam(learning_rate=lr)\n",
        "                    opt_state = optimizer.init(params)\n",
        "\n",
        "                    # Mini-batch training\n",
        "                    num_batches = max(1, len(X_train) // batch_size)\n",
        "\n",
        "                    for epoch in range(50):  # Fewer epochs for tuning\n",
        "                        # Shuffle data\n",
        "                        perm = random.permutation(key, len(X_train))\n",
        "                        key = random.fold_in(key, epoch)  # Update key for next epoch\n",
        "\n",
        "                        # Mini-batch updates\n",
        "                        total_loss = 0.0\n",
        "                        for i in range(num_batches):\n",
        "                            batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "                            X_batch = X_train[batch_idx]\n",
        "                            y_batch = y_train[batch_idx]\n",
        "\n",
        "                            params, opt_state, loss = train_step(\n",
        "                                params, X_batch, y_batch, opt_state,\n",
        "                                dropout_rate=dropout_rate, train=True\n",
        "                            )\n",
        "                            total_loss += loss\n",
        "\n",
        "                        avg_loss = total_loss / num_batches\n",
        "                        if epoch % 10 == 0:\n",
        "                            print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "                    # Evaluate on validation set\n",
        "                    val_accuracy = evaluate(params, X_valid, y_valid, dropout_rate=0.0, train=False)\n",
        "                    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "                    # Record result\n",
        "                    config = {\n",
        "                        'learning_rate': lr,\n",
        "                        'hidden_layers': hidden_layers,\n",
        "                        'dropout_rate': dropout_rate,\n",
        "                        'batch_size': batch_size,\n",
        "                        'val_accuracy': val_accuracy\n",
        "                    }\n",
        "                    results.append(config)\n",
        "\n",
        "                    # Update best model\n",
        "                    if val_accuracy > best_accuracy:\n",
        "                        best_accuracy = val_accuracy\n",
        "                        best_params = params\n",
        "                        best_config = config\n",
        "\n",
        "    print(\"\\n=== Hyperparameter Tuning Results ===\")\n",
        "    for i, res in enumerate(sorted(results, key=lambda x: x['val_accuracy'], reverse=True)):\n",
        "        print(f\"{i+1}. Accuracy: {res['val_accuracy']:.4f} - LR: {res['learning_rate']}, \"\n",
        "              f\"Layers: {res['hidden_layers']}, Dropout: {res['dropout_rate']}, \"\n",
        "              f\"Batch Size: {res['batch_size']}\")\n",
        "\n",
        "    print(f\"\\nBest Configuration: {best_config}\")\n",
        "    return best_params, best_config\n",
        "\n",
        "# Modified evaluation function for hyperparameter tuning\n",
        "def evaluate(params, X, y, dropout_rate=0.0, train=False) -> float:\n",
        "    \"\"\"Evaluate model accuracy with optional dropout\"\"\"\n",
        "    key = random.PRNGKey(99) if train else None\n",
        "    logits = mlp_forward(params, X, dropout_rate=dropout_rate, train=train, key=key)\n",
        "    preds = jax.nn.sigmoid(logits)\n",
        "    binary_preds = (preds > 0.5).astype(jnp.float32)\n",
        "    accuracy = jnp.mean(binary_preds == y)\n",
        "    return float(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVKPdWUfWVVl",
        "outputId": "b5bb940a-d1a7-4c26-dd41-c8af185cb608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Starting Hyperparameter Tuning ===\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.0, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6912\n",
            "Epoch 11 | Avg Loss: 0.6760\n",
            "Epoch 21 | Avg Loss: 0.6739\n",
            "Epoch 31 | Avg Loss: 0.6727\n",
            "Epoch 41 | Avg Loss: 0.6715\n",
            "Validation Accuracy: 0.4975\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.2, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6920\n",
            "Epoch 11 | Avg Loss: 0.6777\n",
            "Epoch 21 | Avg Loss: 0.6752\n",
            "Epoch 31 | Avg Loss: 0.6739\n",
            "Epoch 41 | Avg Loss: 0.6730\n",
            "Validation Accuracy: 0.5045\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.3, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6922\n",
            "Epoch 11 | Avg Loss: 0.6781\n",
            "Epoch 21 | Avg Loss: 0.6756\n",
            "Epoch 31 | Avg Loss: 0.6745\n",
            "Epoch 41 | Avg Loss: 0.6734\n",
            "Validation Accuracy: 0.5072\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.4, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6926\n",
            "Epoch 11 | Avg Loss: 0.6788\n",
            "Epoch 21 | Avg Loss: 0.6768\n",
            "Epoch 31 | Avg Loss: 0.6752\n",
            "Epoch 41 | Avg Loss: 0.6738\n",
            "Validation Accuracy: 0.5025\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.5, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6931\n",
            "Epoch 11 | Avg Loss: 0.6794\n",
            "Epoch 21 | Avg Loss: 0.6775\n",
            "Epoch 31 | Avg Loss: 0.6760\n",
            "Epoch 41 | Avg Loss: 0.6745\n",
            "Validation Accuracy: 0.5022\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.6, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6935\n",
            "Epoch 11 | Avg Loss: 0.6798\n",
            "Epoch 21 | Avg Loss: 0.6777\n",
            "Epoch 31 | Avg Loss: 0.6767\n",
            "Epoch 41 | Avg Loss: 0.6754\n",
            "Validation Accuracy: 0.5225\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.7, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6943\n",
            "Epoch 11 | Avg Loss: 0.6810\n",
            "Epoch 21 | Avg Loss: 0.6786\n",
            "Epoch 31 | Avg Loss: 0.6776\n",
            "Epoch 41 | Avg Loss: 0.6767\n",
            "Validation Accuracy: 0.4693\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.8, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.6954\n",
            "Epoch 11 | Avg Loss: 0.6842\n",
            "Epoch 21 | Avg Loss: 0.6795\n",
            "Epoch 31 | Avg Loss: 0.6783\n",
            "Epoch 41 | Avg Loss: 0.6774\n",
            "Validation Accuracy: 0.5382\n",
            "\n",
            "Trying: lr=0.0001, layers=[128, 64], dropout=0.9, batch_size=32\n",
            "Epoch 1 | Avg Loss: 0.7006\n",
            "Epoch 11 | Avg Loss: 0.6852\n",
            "Epoch 21 | Avg Loss: 0.6823\n",
            "Epoch 31 | Avg Loss: 0.6808\n",
            "Epoch 41 | Avg Loss: 0.6801\n",
            "Validation Accuracy: 0.4458\n",
            "\n",
            "=== Hyperparameter Tuning Results ===\n",
            "1. Accuracy: 0.5382 - LR: 0.0001, Layers: [128, 64], Dropout: 0.8, Batch Size: 32\n",
            "2. Accuracy: 0.5225 - LR: 0.0001, Layers: [128, 64], Dropout: 0.6, Batch Size: 32\n",
            "3. Accuracy: 0.5072 - LR: 0.0001, Layers: [128, 64], Dropout: 0.3, Batch Size: 32\n",
            "4. Accuracy: 0.5045 - LR: 0.0001, Layers: [128, 64], Dropout: 0.2, Batch Size: 32\n",
            "5. Accuracy: 0.5025 - LR: 0.0001, Layers: [128, 64], Dropout: 0.4, Batch Size: 32\n",
            "6. Accuracy: 0.5022 - LR: 0.0001, Layers: [128, 64], Dropout: 0.5, Batch Size: 32\n",
            "7. Accuracy: 0.4975 - LR: 0.0001, Layers: [128, 64], Dropout: 0.0, Batch Size: 32\n",
            "8. Accuracy: 0.4693 - LR: 0.0001, Layers: [128, 64], Dropout: 0.7, Batch Size: 32\n",
            "9. Accuracy: 0.4458 - LR: 0.0001, Layers: [128, 64], Dropout: 0.9, Batch Size: 32\n",
            "\n",
            "Best Configuration: {'learning_rate': 0.0001, 'hidden_layers': [128, 64], 'dropout_rate': 0.8, 'batch_size': 32, 'val_accuracy': 0.538160502910614}\n",
            "\n",
            "=== Training Final Model with Best Hyperparameters ===\n"
          ]
        }
      ],
      "source": [
        "# Run hyperparameter tuning\n",
        "print(\"\\n=== Starting Hyperparameter Tuning ===\")\n",
        "best_params, best_config = tune_hyperparameters()\n",
        "\n",
        "# Train final model with best hyperparameters\n",
        "print(\"\\n=== Training Final Model with Best Hyperparameters ===\")\n",
        "key = random.PRNGKey(0)\n",
        "layer_sizes = [input_dim] + best_config['hidden_layers'] + [1]\n",
        "params = init_mlp_params(layer_sizes, key)\n",
        "\n",
        "# Initialize optimizer with best learning rate\n",
        "optimizer = optax.adam(learning_rate=best_config['learning_rate'])\n",
        "opt_state = optimizer.init(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBoWRfJV4KPI",
        "outputId": "8ca87245-c1aa-4420-f3c4-4c20655a5703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 0.6973 | Train Acc: 0.5278 | Val Acc: 0.4669\n",
            "Epoch 11 | Loss: 0.6830 | Train Acc: 0.5286 | Val Acc: 0.4908\n",
            "Epoch 21 | Loss: 0.6801 | Train Acc: 0.5248 | Val Acc: 0.5311\n",
            "Epoch 31 | Loss: 0.6792 | Train Acc: 0.5377 | Val Acc: 0.5119\n",
            "Epoch 41 | Loss: 0.6784 | Train Acc: 0.5381 | Val Acc: 0.5292\n",
            "Epoch 51 | Loss: 0.6776 | Train Acc: 0.5284 | Val Acc: 0.5432\n",
            "Epoch 61 | Loss: 0.6767 | Train Acc: 0.5268 | Val Acc: 0.5495\n",
            "Epoch 71 | Loss: 0.6763 | Train Acc: 0.5474 | Val Acc: 0.5374\n",
            "Epoch 81 | Loss: 0.6756 | Train Acc: 0.5254 | Val Acc: 0.5487\n",
            "Epoch 91 | Loss: 0.6751 | Train Acc: 0.5418 | Val Acc: 0.5374\n",
            "Epoch 100 | Loss: 0.6749 | Train Acc: 0.5270 | Val Acc: 0.5499\n"
          ]
        }
      ],
      "source": [
        "# Training with mini-batches\n",
        "num_epochs = 100\n",
        "batch_size = best_config['batch_size']\n",
        "num_batches = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Shuffle data\n",
        "    perm = random.permutation(key, len(X_train))\n",
        "    key = random.fold_in(key, epoch)\n",
        "\n",
        "    # Mini-batch updates\n",
        "    total_loss = 0.0\n",
        "    for i in range(num_batches):\n",
        "        batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "        X_batch = X_train[batch_idx]\n",
        "        y_batch = y_train[batch_idx]\n",
        "\n",
        "        params, opt_state, loss = train_step(\n",
        "            params, X_batch, y_batch, opt_state,\n",
        "            dropout_rate=best_config['dropout_rate'], train=True\n",
        "        )\n",
        "        total_loss += loss\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
        "        train_acc = evaluate(params, X_train, y_train, dropout_rate=0.0, train=False)\n",
        "        val_acc = evaluate(params, X_valid, y_valid, dropout_rate=0.0, train=False)\n",
        "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcQjGyOfTKK5",
        "outputId": "2b460511-013d-4441-ee39-2840d3857fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Validation Accuracy: 0.5499022007\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation\n",
        "final_accuracy = evaluate(params, X_valid, y_valid, dropout_rate=0.0, train=False)\n",
        "print(f\"\\nFinal Validation Accuracy: {final_accuracy:.10f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpWuQHFdc8Vr"
      },
      "source": [
        "### 3. Bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQbCbI3anwx0"
      },
      "outputs": [],
      "source": [
        "y_train = acl_train_embedded[:, 0].reshape(-1, 1)\n",
        "X_train = acl_train_embedded[:, 1:]\n",
        "y_valid = acl_valid_embedded[:, 0].reshape(-1, 1)\n",
        "X_valid = acl_valid_embedded[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKIGgpLiT88g"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "\n",
        "# List of classifiers to use\n",
        "classifiers = [\n",
        "    LogisticRegression(),\n",
        "    SVC(kernel='linear'),\n",
        "    RandomForestClassifier(n_estimators=100),\n",
        "    KNeighborsClassifier(n_neighbors=5)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V9BjbUBOc-VZ",
        "outputId": "83235d80-afa7-4421-8f9b-ace28533156f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ],
      "source": [
        "# Number of bootstrap samples\n",
        "n_bootstrap = 10\n",
        "\n",
        "# Create an empty list to store models\n",
        "trained_classifiers = []\n",
        "\n",
        "# Generate bootstrap samples and train each model\n",
        "for clf in classifiers:\n",
        "    clf_bootstrap_models = []\n",
        "    for _ in range(n_bootstrap):\n",
        "        # Generate bootstrap sample (with replacement)\n",
        "        X_resampled, y_resampled = resample(X_train, y_train, n_samples=X_train.shape[0], random_state=1000)\n",
        "        clf_clone = clf.__class__()  # Create a fresh clone of the classifier\n",
        "        clf_clone.fit(X_resampled, y_resampled)\n",
        "        clf_bootstrap_models.append(clf_clone)\n",
        "\n",
        "    # Append the trained bootstrap models to the list of classifiers\n",
        "    trained_classifiers.append(clf_bootstrap_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKY33t9adCe5",
        "outputId": "85d3cd1d-acf5-49b5-cc0a-bea312ee87e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bagging Accuracy: 0.5353250026\n"
          ]
        }
      ],
      "source": [
        "# Function to aggregate predictions using majority voting\n",
        "def bagging_predict(X):\n",
        "    predictions = []\n",
        "\n",
        "    for clf_bootstrap_models in trained_classifiers:\n",
        "        clf_preds = np.zeros((X.shape[0], len(clf_bootstrap_models)))\n",
        "\n",
        "        for idx, model in enumerate(clf_bootstrap_models):\n",
        "            clf_preds[:, idx] = model.predict(X)\n",
        "\n",
        "        # Average predictions for each classifier group\n",
        "        avg_pred = np.mean(clf_preds, axis=1)\n",
        "        # Convert to binary predictions using threshold\n",
        "        binary_pred = (avg_pred >= 0.5).astype(int)\n",
        "        predictions.append(binary_pred)\n",
        "\n",
        "    # Final ensemble prediction\n",
        "    final_pred = np.mean(predictions, axis=0)\n",
        "    return (final_pred >= 0.5).astype(int)\n",
        "\n",
        "# Apply bagging prediction\n",
        "final_predictions = bagging_predict(X_valid)\n",
        "\n",
        "# Evaluate final predictions (accuracy)\n",
        "accuracy = np.mean(final_predictions == y_valid)\n",
        "print(f\"Bagging Accuracy: {accuracy:.10f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_q_QB313ORr"
      },
      "source": [
        "### 4. Fine-tuned LLM *FinBert* with DoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RJxU9FUf8jcw",
        "outputId": "82ff355f-e5ac-420b-f963-45d34b016d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.37.2)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.17.0\n",
            "    Uninstalling accelerate-0.17.0:\n",
            "      Successfully uninstalled accelerate-0.17.0\n",
            "Successfully installed accelerate-1.6.0\n",
            "Collecting accelerate==0.17.0\n",
            "  Using cached accelerate-0.17.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (2.2.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.17.0) (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->accelerate==0.17.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->accelerate==0.17.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->accelerate==0.17.0) (3.0.2)\n",
            "Using cached accelerate-0.17.0-py3-none-any.whl (212 kB)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.6.0\n",
            "    Uninstalling accelerate-1.6.0:\n",
            "      Successfully uninstalled accelerate-1.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.10.0 requires accelerate>=0.21.0, but you have accelerate 0.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets scikit-learn peft numpy torch\n",
        "!pip install accelerate==0.17.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RCNFttDn_RrO"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.37.2\n",
        "!pip install peft==0.10.0\n",
        "# version debugging referring to https://stackoverflow.com/questions/79273647/cannot-import-name-encoderdecodercache-from-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L39JyTzV86s3"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTbohJvY4oDb",
        "outputId": "03b7cc95-32c2-4c36-822e-ba63ea4d71e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained 'ProsusAI/finbert' model and tokenizer\n",
        "model_name = 'ProsusAI/finbert'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "finbert = BertForSequenceClassification.from_pretrained(model_name)  # Binary classification\n",
        "finbert.config.num_labels = 2\n",
        "finbert.num_labels = 2\n",
        "\n",
        "original_finbert = finbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYaATiVp60Kj",
        "outputId": "97b6540a-4d38-42a4-95f9-cdf2e62ecd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 963,078 || all params: 110,446,856 || trainable%: 0.8719831735183118\n"
          ]
        }
      ],
      "source": [
        "# Add dropout to the classifier for better regularization\n",
        "\n",
        "# First apply the base model modifications\n",
        "dropout_prob = 0.5\n",
        "finbert.classifier = nn.Sequential(\n",
        "    nn.Dropout(dropout_prob),\n",
        "    nn.Linear(finbert.config.hidden_size, finbert.config.num_labels)\n",
        ")\n",
        "\n",
        "# Configure PEFT with LoRA specifically for binary classification\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.5,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"query\", \"key\", \"value\", \"output.dense\"],\n",
        ")\n",
        "\n",
        "# Wrap the model with LoRA\n",
        "finbert = get_peft_model(finbert, peft_config)\n",
        "\n",
        "# Manually ensure the classifier parameters are trainable\n",
        "for param in finbert.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "finbert.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqxrF-0ZHzvh"
      },
      "source": [
        "### Setup data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7089b945d50d4c8ab2bbaded97f1ca98",
            "ab0d59b4225d44d1887fe23b69f67912",
            "640381bb940b474e8ee2b9d12e2e2eef",
            "26d5b69b79b14e1fac39cb8562750f49",
            "66fe9607ab8842d0b96a62612cfbe450",
            "eb66125b3e424fabb6b7ec9d67d5bb5f",
            "43d3007c0f11446e87eba71d395c60f9",
            "fbf54e0922de40ed82751ebcb4331771",
            "64213c7a4df64c2ca664ef00263a4b8a",
            "2faf066ca3d74348b89d496efb108934",
            "ec9b5c60740b4dd3b16db0bc9430f5f8",
            "d8ae16d489394b07be41d56e96646370",
            "f1364bda5a8c40ff9c48ff1c65b6856a",
            "8308fa4d767a4042a434ac547f1ee51b",
            "2a28d70f611747278b045d4aba77261d",
            "0b300108d9da4ea8b73d16ba28201621",
            "27821ffe452f461ba2abfde6fa322254",
            "7b33d2ab9fe4489c9167df50a9c246bc",
            "0704f1163773466daba7f077fc004fd4",
            "6ccdcea722404c7f91759173d39e2055",
            "5d3b88db45464c599511c9a13e7007ea",
            "835dd1d7860943b1b681039d18073cff"
          ]
        },
        "id": "KeK4WgPkH1dx",
        "outputId": "dfdd360d-16dd-4a60-cd62-fbeaef0b9d03"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7089b945d50d4c8ab2bbaded97f1ca98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20781 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8ae16d489394b07be41d56e96646370",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2555 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "acl_train_ds = Dataset.from_pandas(acl_train_df)\n",
        "acl_valid_ds = Dataset.from_pandas(acl_valid_df)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        padding=True,            # Padding handled dynamically by the DataCollator\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "acl_train_token = acl_train_ds.map(tokenize_function, batched=True)\n",
        "acl_valid_token = acl_valid_ds.map(tokenize_function, batched=True)\n",
        "\n",
        "acl_train_token = acl_train_token.rename_column(\"gold\", \"label\")\n",
        "acl_valid_token = acl_valid_token.rename_column(\"gold\", \"label\")\n",
        "\n",
        "acl_train_token.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "acl_valid_token.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6qD8Mu3Giz9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "train_dataloader = DataLoader(acl_train_token, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
        "valid_dataloader = DataLoader(acl_valid_token, batch_size=16, shuffle=False, collate_fn=data_collator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ura0tssPGfo8"
      },
      "source": [
        "### Train with torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BGuX32eGjRA",
        "outputId": "898f07a1-c197-49eb-d450-242c10f2a42d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "finbert.to(device)\n",
        "print(device)\n",
        "\n",
        "# set up optimizer\n",
        "optimizer = AdamW(finbert.parameters(), lr=2e-5, weight_decay=0.1)\n",
        "\n",
        "# set up loss function\n",
        "class_weights = torch.tensor([1.0, 1.0], device=device)  # adjust per class stats\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Add early stopping mechanism\n",
        "best_val_accuracy = 0\n",
        "patience = 2\n",
        "early_stop_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "# Add learning rate scheduler for better convergence\n",
        "num_epochs = 5  # Increase epochs since we have early stopping\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"cosine\",  # Use cosine schedule for better convergence\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=int(0.1 * len(train_dataloader) * num_epochs),  # 10% warmup\n",
        "    num_training_steps=len(train_dataloader) * num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSD0569AGu7l",
        "outputId": "e15b2ec6-cbd6-40bd-f192-aea338879653"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 1299/1299 [03:10<00:00,  6.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Avg training loss: 0.7119\n",
            "Validation Loss: 0.6930, Accuracy: 0.5182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 1299/1299 [03:10<00:00,  6.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Avg training loss: 0.6973\n",
            "Validation Loss: 0.6953, Accuracy: 0.4869\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 1299/1299 [03:10<00:00,  6.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Avg training loss: 0.6887\n",
            "Validation Loss: 0.6970, Accuracy: 0.4814\n",
            "Early stopping triggered after 3 epochs\n"
          ]
        }
      ],
      "source": [
        "# torch training loop with regularization techniques\n",
        "for epoch in range(num_epochs):\n",
        "    finbert.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Enable dropout during training (it's enabled by default in train mode)\n",
        "        outputs = finbert(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Add L2 regularization if needed\n",
        "        # for param in finbert.parameters():\n",
        "        #    loss += 0.01 * torch.sum(param ** 2)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(finbert.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1} - Avg training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    finbert.eval()\n",
        "    correct, total = 0, 0\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = finbert(**batch)\n",
        "            val_loss += outputs.loss.item()\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "            correct += (predictions == batch[\"labels\"]).sum().item()\n",
        "            total += batch[\"labels\"].size(0)\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    avg_val_loss = val_loss / len(valid_dataloader)\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        early_stop_counter = 0\n",
        "        # Save best model state\n",
        "        best_model_state = {k: v.cpu().clone() for k, v in finbert.state_dict().items()}\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    if early_stop_counter >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1bzew40G9da",
        "outputId": "631a5403-f11a-43e1-b8c3-4b86d3e3c55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded best model with validation accuracy: 0.5181996086\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('finbert-lora-semantic/tokenizer_config.json',\n",
              " 'finbert-lora-semantic/special_tokens_map.json',\n",
              " 'finbert-lora-semantic/vocab.txt',\n",
              " 'finbert-lora-semantic/added_tokens.json')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the best model state before saving\n",
        "if best_model_state is not None:\n",
        "    finbert.load_state_dict(best_model_state)\n",
        "    print(f\"Loaded best model with validation accuracy: {best_val_accuracy:.10f}\")\n",
        "\n",
        "# save the fine-tuned model\n",
        "finbert.save_pretrained(\"finbert-lora-semantic\")\n",
        "tokenizer.save_pretrained(\"finbert-lora-semantic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVGyrAyTSCWK"
      },
      "outputs": [],
      "source": [
        "# Evaluate the original FinBERT (before LoRA fine-tuning)\n",
        "\n",
        "# Evaluation function for models\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            val_loss += outputs.loss.item()\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "            correct += (predictions == batch[\"labels\"]).sum().item()\n",
        "            total += batch[\"labels\"].size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = val_loss / len(dataloader)\n",
        "    return accuracy, avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6104ed9SD8X",
        "outputId": "8b9e1c62-f6cd-4c1a-a0cf-ac8e2e7eb06d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluating Original FinBERT Model ===\n",
            "Original FinBERT - Validation Loss: 0.6930, Accuracy: 0.5181996086\n"
          ]
        }
      ],
      "source": [
        "# Evaluate original FinBERT\n",
        "print(\"\\n=== Evaluating Original FinBERT Model ===\")\n",
        "original_finbert.to(device)\n",
        "original_accuracy, original_loss = evaluate_model(original_finbert, valid_dataloader, device)\n",
        "print(f\"Original FinBERT - Validation Loss: {original_loss:.4f}, Accuracy: {original_accuracy:.10f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0704f1163773466daba7f077fc004fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b300108d9da4ea8b73d16ba28201621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d5b69b79b14e1fac39cb8562750f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2faf066ca3d74348b89d496efb108934",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9b5c60740b4dd3b16db0bc9430f5f8",
            "value": " 20781/20781 [01:38&lt;00:00, 194.79 examples/s]"
          }
        },
        "27821ffe452f461ba2abfde6fa322254": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a28d70f611747278b045d4aba77261d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d3b88db45464c599511c9a13e7007ea",
            "placeholder": "​",
            "style": "IPY_MODEL_835dd1d7860943b1b681039d18073cff",
            "value": " 2555/2555 [00:12&lt;00:00, 202.13 examples/s]"
          }
        },
        "2faf066ca3d74348b89d496efb108934": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d3007c0f11446e87eba71d395c60f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d3b88db45464c599511c9a13e7007ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640381bb940b474e8ee2b9d12e2e2eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf54e0922de40ed82751ebcb4331771",
            "max": 20781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64213c7a4df64c2ca664ef00263a4b8a",
            "value": 20781
          }
        },
        "64213c7a4df64c2ca664ef00263a4b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66fe9607ab8842d0b96a62612cfbe450": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ccdcea722404c7f91759173d39e2055": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7089b945d50d4c8ab2bbaded97f1ca98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab0d59b4225d44d1887fe23b69f67912",
              "IPY_MODEL_640381bb940b474e8ee2b9d12e2e2eef",
              "IPY_MODEL_26d5b69b79b14e1fac39cb8562750f49"
            ],
            "layout": "IPY_MODEL_66fe9607ab8842d0b96a62612cfbe450"
          }
        },
        "7b33d2ab9fe4489c9167df50a9c246bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8308fa4d767a4042a434ac547f1ee51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0704f1163773466daba7f077fc004fd4",
            "max": 2555,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ccdcea722404c7f91759173d39e2055",
            "value": 2555
          }
        },
        "835dd1d7860943b1b681039d18073cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab0d59b4225d44d1887fe23b69f67912": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb66125b3e424fabb6b7ec9d67d5bb5f",
            "placeholder": "​",
            "style": "IPY_MODEL_43d3007c0f11446e87eba71d395c60f9",
            "value": "Map: 100%"
          }
        },
        "d8ae16d489394b07be41d56e96646370": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1364bda5a8c40ff9c48ff1c65b6856a",
              "IPY_MODEL_8308fa4d767a4042a434ac547f1ee51b",
              "IPY_MODEL_2a28d70f611747278b045d4aba77261d"
            ],
            "layout": "IPY_MODEL_0b300108d9da4ea8b73d16ba28201621"
          }
        },
        "eb66125b3e424fabb6b7ec9d67d5bb5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9b5c60740b4dd3b16db0bc9430f5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1364bda5a8c40ff9c48ff1c65b6856a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27821ffe452f461ba2abfde6fa322254",
            "placeholder": "​",
            "style": "IPY_MODEL_7b33d2ab9fe4489c9167df50a9c246bc",
            "value": "Map: 100%"
          }
        },
        "fbf54e0922de40ed82751ebcb4331771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
